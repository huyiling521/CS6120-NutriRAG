# ğŸ¥¦ NutriRAG: A RAG-Powered Nutrition Assistant

**NutriRAG** is a Retrieval-Augmented Generation (RAG) system designed to help users get personalized meal plans, recipe suggestions, and nutritional guidance powered by a large language model (LLM). Users can ask for protein-rich meals, healthy substitutes, or low-calorie recipes, and the system retrieves real-world recipe data and generates markdown-based meal plans.

---

## ğŸ—‚ï¸ Project Structure

```plaintext
CS6120-NutriRAG/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py                # FastAPI entry point
â”‚   â”œâ”€â”€ model_loader.py        # RAG component loader (LLM, retriever, chains)
â”‚   â”œâ”€â”€ prompts.py             # Prompt templates for each stage of the pipeline
â”‚   â”œâ”€â”€ rag_chain.py           # Core RAG pipeline implementation
â”‚   â”œâ”€â”€ routes.py              # FastAPI route definitions
â”‚   â”œâ”€â”€ schemas.py             # Pydantic schemas for request/response models
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ longchain_convert.py   # Helper script to build FAISS index from metadata
â”‚   â””â”€â”€ index/
â”‚       â”œâ”€â”€ combined_metadata.json      # Source metadata for vector index
â”‚       â””â”€â”€ langchain_faiss/
â”‚           â”œâ”€â”€ index.faiss            # FAISS vector store
â”‚           â””â”€â”€ index.pkl              # Index mapping metadata
â”‚
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ app.py                # Streamlit frontend for chat-based interface
â”‚   â””â”€â”€ .env                  # Frontend config (e.g., BACKEND_URL)
â”‚
â”œâ”€â”€ requirements.txt          # Python dependencies
â”œâ”€â”€ README.md                 # Project description and setup guide
â””â”€â”€ .env                      # Backend config (e.g., OPENAI_API_KEY)
```

---

## âš™ï¸ Quick Start Guide

### 1. Clone the Repository

```bash
git clone https://github.com/your-org/CS6120-NutriRAG.git
cd CS6120-NutriRAG
```

### 2. Install Dependencies and download data files

```bash
pip install -r requirements.txt
cd ./CS6120-NutriRAG/data/
gdown 1_ouVNYI2SPzjhLY4iQ18Gjy-U7XWCpb4
gdown --folder 1fgvui1M1kAd4YTu6aEoXJ083QfXhchGh
```

### 3. Configure Environment Variables

Create a `.env` file under both `/app/` and `/frontend/`.

**`app/.env`**

```env
OPENAI_API_KEY=your-openai-api-key
ORIGINS=http://localhost:8501
```

**`frontend/.env`**

```env
BACKEND_URL=http://localhost:8000
```

---

### 4. Launch the Backend (FastAPI)

```bash
uvicorn app.main:app --reload --port 8000
```

---

### 5. Launch the Frontend (Streamlit)

```bash
streamlit run frontend/app.py
```

---

## ğŸ’¡ Features

- Intent & Entity Extraction with LLM
- Query Rewriting for Semantic Search
- FAISS-based Vector Retrieval
- Context-Aware Answer Generation
- Streamlit Chat Interface

---

## ğŸ“¦ Docker Support

Coming soon: `Dockerfile` for full containerized deployment.
